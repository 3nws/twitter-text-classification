{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Enes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import nltk\n",
    "import preprocessor as p\n",
    "p.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.HASHTAG)\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import TweetTokenizer, RegexpTokenizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...\n",
       "1        advice Talk to your neighbours family to excha...\n",
       "2        Coronavirus Australia: Woolworths to give elde...\n",
       "3        My food stock is not the only one which is emp...\n",
       "4        Me, ready to go at supermarket during the #COV...\n",
       "                               ...                        \n",
       "41152    Airline pilots offering to stock supermarket s...\n",
       "41153    Response to complaint not provided citing COVI...\n",
       "41154    You know itÂs getting tough when @KameronWild...\n",
       "41155    Is it wrong that the smell of hand sanitizer i...\n",
       "41156    @TartiiCat Well new/used Rift S are going for ...\n",
       "Name: OriginalTweet, Length: 41157, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "DATASET_ENCODING = \"ISO-8859-1\"\n",
    "\n",
    "dataset = pd.read_csv('./Corona_NLP_train.csv', delimiter=',', encoding=DATASET_ENCODING)\n",
    "\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "\n",
    "dataset.head()\n",
    "\n",
    "def preprocess_tweets(tweet):\n",
    "    tweet = p.clean(tweet)\n",
    "    tokens = tweet.split()\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    return ' '.join(stemmed_tokens)\n",
    "\n",
    "X = dataset['OriginalTweet']\n",
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                  and and\n",
       "1        advic talk to your neighbour famili to exchang...\n",
       "2        coronavirus australia: woolworth to give elder...\n",
       "3        my food stock is not the only one which is emp...\n",
       "4        me, readi to go at supermarket during the outb...\n",
       "                               ...                        \n",
       "41152    airlin pilot offer to stock supermarket shelv ...\n",
       "41153    respons to complaint not provid cite covid-19 ...\n",
       "41154    you know itâ get tough when is ration toilet ...\n",
       "41155    is it wrong that the smell of hand sanit is st...\n",
       "41156    well new/us rift s are go for $700.00 on amazo...\n",
       "Name: OriginalTweet, Length: 41157, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "X = X.apply(preprocess_tweets)\n",
    "\n",
    "y = dataset['Sentiment']\n",
    "\n",
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                   Neutral\n",
       "1                  Positive\n",
       "2                  Positive\n",
       "3                  Positive\n",
       "4        Extremely Negative\n",
       "                ...        \n",
       "41152               Neutral\n",
       "41153    Extremely Negative\n",
       "41154              Positive\n",
       "41155               Neutral\n",
       "41156              Negative\n",
       "Name: Sentiment, Length: 41157, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y\n",
    "# X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)\n",
    "\n",
    "# X_train.shape, X_test.shape\n",
    "\n",
    "# creating our pipeline that will return an estimator\n",
    "pipeline = Pipeline([('tfidf', TfidfVectorizer(max_features=20000, ngram_range=(1,2), tokenizer=token.tokenize)), ('clf', SVC(probability=True))])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = pipeline.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(pipeline.predict_proba(sub_main))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# test_tweet = \"scandinavia #news:  norway : it's illegal for employers to require covid  passports  denmark\\\n",
    "#     sweden : they won't be bringing in covid  vaccination passports  #holdtheline #enoughisenough #nomedicalapartheid #nomasks #nomorelockdowns #openforall #corona #coronavirus\"\n",
    "# # test_tweet2 = \"everyone should get vaccinated as soon as possible\"\n",
    "# vector = tfidf.transform([test_tweet])\n",
    "\n",
    "# print(svc.predict(vector))\n",
    "\n",
    "acc = int(accuracy_score(y_test, y_pred)*100)\n",
    "\n",
    "# exporting the model and the trained vectorizer\n",
    "pickle.dump(svc, open(f'./models/SVC_model_{acc}', 'wb'))\n",
    "pickle.dump(tfidf, open(f'./vector/tfidf_vectorizer_{acc}', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "599e51aa143538ccec1c7ab4b528efe64565e20e387dbc49eb00bf436cfb223b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
