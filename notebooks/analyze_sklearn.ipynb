{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "algorithm = 'ComplementNB'\n",
    "algo_short = \"cnb\"\n",
    "acc = '76'\n",
    "dataset_dir = 'sentiment140'\n",
    "\n",
    "algorithms = [\n",
    "    'MultinomialNB', \n",
    "    'ComplementNB',\n",
    "    'xgb',\n",
    "    'rfc',\n",
    "    'LogisticRegression',\n",
    "    'LinearSVC',\n",
    "    'VotingClassifier',\n",
    "    ]\n",
    "algos_short = [\n",
    "    'mnb', \n",
    "    'cnb',\n",
    "    'xgb',\n",
    "    'rfc',\n",
    "    'lrg',\n",
    "    'lsvc',\n",
    "    'vth',\n",
    "    ]\n",
    "accs = [\n",
    "    '77',\n",
    "    '76',\n",
    "    '76',\n",
    "    '72',\n",
    "    '78',\n",
    "    '76',\n",
    "    '77'\n",
    "    ]\n",
    "\n",
    "vaccines = [\"biontech\", \"janssen\", \"moderna\",\n",
    "            \"oxford\", \"sinopharm\", \"sinovac\", \"sputnik\"]\n",
    "\n",
    "\n",
    "# n_grams = [(1, 1), (1, 2)]\n",
    "# n_grams = [(1, 1)]\n",
    "n_grams = [(1, 2)]\n",
    "years = [\"2020\", \"2021\", \"2022\"]\n",
    "months = [\"january\", \"february\", \"march\", \"april\", \"may\", \"june\",\n",
    "          \"july\", \"august\", \"september\", \"october\", \"november\", \"december\"]\n",
    "war = []\n",
    "\n",
    "for file in os.listdir(\"../data/\"):\n",
    "    war.append(file)\n",
    "\n",
    "## MONTHS\n",
    "\n",
    "for n_gram in n_grams:\n",
    "    for year in years:\n",
    "        for month in months:\n",
    "            vectorizer_path = f\"../vectors/vectorizer_{dataset_dir}_{n_gram}.pkl\"\n",
    "\n",
    "            model_path = f\"../models/{algorithm}_{dataset_dir}_{acc}_{n_gram}.pkl\"\n",
    "\n",
    "            # already processed\n",
    "            try:\n",
    "                df = pd.read_csv(f'../{year}-data/covid-{month}.csv', delimiter=',')\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            df = df.drop_duplicates()\n",
    "\n",
    "            df = df[['tweet', 'sentiment']]\n",
    "\n",
    "            tfidf = joblib.load(vectorizer_path)\n",
    "\n",
    "            model = joblib.load(model_path)\n",
    "\n",
    "            X = df.iloc[:, 0].fillna(' ')\n",
    "\n",
    "            tweets = X\n",
    "\n",
    "            num_of_tweets_analyzed = len(tweets)\n",
    "\n",
    "            y_pred = tfidf.transform(X)\n",
    "\n",
    "            predictions = model.predict(y_pred)\n",
    "\n",
    "            # saving tweets to csv\n",
    "            tweets.to_csv(f'../analysis/tweets-{month}-{year}-{n_gram}.csv')\n",
    "            # saving sentiment predictions to csv\n",
    "            np.savetxt(f'../analysis/predictions-{month}-{year}-{n_gram}.csv',\n",
    "                    predictions, delimiter=',', fmt=('%s'))\n",
    "\n",
    "            # adding sentiment column to the beginning\n",
    "            df = pd.read_csv(\n",
    "                f'../analysis/predictions-{month}-{year}-{n_gram}.csv', header=None)\n",
    "            df.rename(columns={0: 'sentiment'}, inplace=True)\n",
    "            # save to new csv file\n",
    "            df.to_csv(\n",
    "                f'../analysis/predictions-{month}-{year}-{n_gram}.csv', index=False)\n",
    "\n",
    "            # merging tweets and predictions\n",
    "            filenames = [f'../analysis/tweets-{month}-{year}-{n_gram}.csv',\n",
    "                         f'../analysis/predictions-{month}-{year}-{n_gram}.csv']\n",
    "            dfs = []\n",
    "            for filename in filenames:\n",
    "                # read the csv, making sure the first two columns are str\n",
    "                df = pd.read_csv(filename, header=None, converters={0: str, 1: str})\n",
    "                # change the column names so they won't collide during concatenation\n",
    "                df.columns = [filename + str(cname) for cname in df.columns]\n",
    "                dfs.append(df)\n",
    "\n",
    "            # concatenate them horizontally\n",
    "            merged = pd.concat(dfs, axis=1)\n",
    "            # write it out\n",
    "            merged.to_csv(\n",
    "                f\"../analysis/merged-{month}-{year}-{n_gram}.csv\", header=None, index=None)\n",
    "\n",
    "            df = pd.read_csv(f'../analysis/merged-{month}-{year}-{n_gram}.csv')\n",
    "\n",
    "            labels = ['negative', 'positive']\n",
    "\n",
    "            title_type = df.groupby('sentiment').agg('count')\n",
    "\n",
    "            type_labels = ['positive', 'negative']\n",
    "            type_counts = title_type.tweet.sort_values()\n",
    "\n",
    "            colors = ['g', 'r']\n",
    "\n",
    "            plt.subplot(\n",
    "                aspect=1, title=f'Percentage of tweets pro or against vaccination in {month.capitalize()} {year}\\nClassified {num_of_tweets_analyzed} tweets.')\n",
    "            type_show_ids = plt.pie(type_counts, labels=type_labels,\n",
    "                                    autopct='%1.1f%%', shadow=True, colors=colors)\n",
    "            plt.savefig(f\"../visuals/{algo_short}/{month}-{year}-{n_gram}.png\")\n",
    "            plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## WAR!\n",
    "for al_long, al_short, acc1 in zip(algorithms, algos_short, accs):  \n",
    "    for n_gram in n_grams:\n",
    "        vectorizer_path = f\"../vectors/vectorizer_{dataset_dir}_{n_gram}_1.pkl\"\n",
    "        model_path = f\"../models/{al_long}_{dataset_dir}_{acc1}_{n_gram}.pkl\"\n",
    "        tfidf = joblib.load(vectorizer_path)\n",
    "        model = joblib.load(model_path)\n",
    "        accs0 = []\n",
    "        for lang in war:\n",
    "                print(lang)\n",
    "                # already processed\n",
    "                df = pd.read_csv(f'../data/{lang}', delimiter=',')\n",
    "\n",
    "                df = df.drop_duplicates()\n",
    "\n",
    "                df = df[['tweet', \"translate\", 'sentiment']]\n",
    "                \n",
    "                if not lang == 'war.csv' and not lang == 'war2.csv':\n",
    "                    df['tweet'] = df['translate']\n",
    "\n",
    "                print(df.head())\n",
    "                X = df.iloc[:, 0].fillna(' ')\n",
    "\n",
    "                tweets = X\n",
    "\n",
    "                num_of_tweets_analyzed = len(tweets)\n",
    "\n",
    "                y_pred = tfidf.transform(X)\n",
    "\n",
    "                predictions = model.predict(y_pred)\n",
    "                print(np.count_nonzero(predictions == 1), np.count_nonzero(predictions == 0))\n",
    "                \n",
    "                # saving tweets to csv\n",
    "                tweets.to_csv(f'../analysis/tweets-{lang}.csv')\n",
    "                # saving sentiment predictions to csv\n",
    "                np.savetxt(f'../analysis/predictions-{lang}.csv',\n",
    "                        predictions, delimiter=',', fmt=('%s'))\n",
    "\n",
    "                # adding sentiment column to the beginning\n",
    "                df = pd.read_csv(\n",
    "                    f'../analysis/predictions-{lang}.csv', header=None)\n",
    "                df.rename(columns={0: 'sentiment'}, inplace=True)\n",
    "                # save to new csv file\n",
    "                df.to_csv(\n",
    "                    f'../analysis/predictions-{lang}.csv', index=False)\n",
    "\n",
    "                # merging tweets and predictions\n",
    "                filenames = [f'../analysis/tweets-{lang}.csv',\n",
    "                            f'../analysis/predictions-{lang}.csv']\n",
    "                dfs = []\n",
    "                for filename in filenames:\n",
    "                    # read the csv, making sure the first two columns are str\n",
    "                    df = pd.read_csv(filename, header=None, converters={0: str, 1: str})\n",
    "                    # change the column names so they won't collide during concatenation\n",
    "                    df.columns = [filename + str(cname) for cname in df.columns]\n",
    "                    dfs.append(df)\n",
    "\n",
    "                # concatenate them horizontally\n",
    "                merged = pd.concat(dfs, axis=1)\n",
    "                # write it out\n",
    "                merged.to_csv(\n",
    "                    f\"../analysis/merged-{lang}.csv\", header=None, index=None)\n",
    "\n",
    "                df = pd.read_csv(f'../analysis/merged-{lang}.csv')\n",
    "\n",
    "\n",
    "                title_type = df.groupby('sentiment').agg('count')\n",
    "\n",
    "                type_labels = ['positive', 'negative']\n",
    "                type_counts = title_type.tweet.sort_values()\n",
    "                accs0.append(type_counts)\n",
    "\n",
    "\n",
    "    accs = np.array(accs0)\n",
    "    f2 = lambda x: [round(x[0]/(x[0]+x[1])*100, 2), round(x[1]/(x[0]+x[1])*100, 2)]\n",
    "    accs = [f2(x) for x in accs]\n",
    "    accs\n",
    "    # counts = [x[0]+x[1] for x in accs0]\n",
    "    # counts\n",
    "    langs = [\"french\", \"german\", \"italian\", \"norwegian\", \"polish\", \"russian\", \"spanish\", \"english\"]\n",
    "    # plt.bar(langs, counts)\n",
    "    # plt.show()\n",
    "        \n",
    "    from cycler import cycler\n",
    "\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.xticks(rotation=90)\n",
    "    print(accs)\n",
    "    plt.rc('axes', prop_cycle=(cycler('color', ['g', 'r'])))\n",
    "    ax.plot(langs, accs, ls='-', marker='o', label=['Positive', 'Negative'])  \n",
    "\n",
    "    plt.xlabel(\"Language\")\n",
    "    plt.ylabel(\"Percentage\")\n",
    "    plt.title(f\"Positive and Negative Sentiment Across Languages with {al_long}\")\n",
    "    ax.legend()\n",
    "    plt.savefig(f\"../visuals/yayin/{al_short}/war.png\")\n",
    "    plt.show()\n",
    "\n",
    "for n_gram in n_grams:\n",
    "    for vaccine in vaccines:\n",
    "        vectorizer_path = f\"../vectors/vectorizer_{dataset_dir}_{n_gram}.pkl\"\n",
    "\n",
    "        model_path = f\"../models/{algorithm}_{dataset_dir}_{acc}_{n_gram}.pkl\"\n",
    "\n",
    "        # already processed\n",
    "        try:\n",
    "            df = pd.read_csv(f'../vaccines/{vaccine}.csv', delimiter=',')\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "        print(df.head())\n",
    "        df = df.drop_duplicates()\n",
    "\n",
    "        df = df[['tweet', 'sentiment']]\n",
    "\n",
    "        tfidf = joblib.load(vectorizer_path)\n",
    "\n",
    "        model = joblib.load(model_path)\n",
    "\n",
    "        X = df.iloc[:, 0].fillna(' ')\n",
    "\n",
    "        tweets = X\n",
    "\n",
    "        num_of_tweets_analyzed = len(tweets)\n",
    "\n",
    "        y_pred = tfidf.transform(X)\n",
    "\n",
    "        predictions = model.predict(y_pred)\n",
    "\n",
    "        # saving tweets to csv\n",
    "        tweets.to_csv(f'../analysis/tweets-{vaccine}-{n_gram}.csv')\n",
    "        # saving sentiment predictions to csv\n",
    "        np.savetxt(f'../analysis/predictions-{vaccine}-{n_gram}.csv',\n",
    "                predictions, delimiter=',', fmt=('%s'))\n",
    "\n",
    "        # adding sentiment column to the beginning\n",
    "        df = pd.read_csv(\n",
    "            f'../analysis/predictions-{vaccine}-{n_gram}.csv', header=None)\n",
    "        df.rename(columns={0: 'sentiment'}, inplace=True)\n",
    "        # save to new csv file\n",
    "        df.to_csv(\n",
    "            f'../analysis/predictions-{vaccine}-{n_gram}.csv', index=False)\n",
    "\n",
    "        # merging tweets and predictions\n",
    "        filenames = [f'../analysis/tweets-{vaccine}-{n_gram}.csv',\n",
    "                        f'../analysis/predictions-{vaccine}-{n_gram}.csv']\n",
    "        dfs = []\n",
    "        for filename in filenames:\n",
    "            # read the csv, making sure the first two columns are str\n",
    "            df = pd.read_csv(filename, header=None, converters={0: str, 1: str})\n",
    "            # change the column names so they won't collide during concatenation\n",
    "            df.columns = [filename + str(cname) for cname in df.columns]\n",
    "            dfs.append(df)\n",
    "\n",
    "        # concatenate them horizontally\n",
    "        merged = pd.concat(dfs, axis=1)\n",
    "        # write it out\n",
    "        merged.to_csv(\n",
    "            f\"../analysis/merged-{vaccine}-{n_gram}.csv\", header=None, index=None)\n",
    "\n",
    "        df = pd.read_csv(f'../analysis/merged-{vaccine}-{n_gram}.csv')\n",
    "\n",
    "        labels = ['negative', 'positive']\n",
    "\n",
    "        title_type = df.groupby('sentiment').agg('count')\n",
    "\n",
    "        type_labels = ['positive', 'negative']\n",
    "        type_counts = title_type.tweet.sort_values()\n",
    "\n",
    "        colors = ['g', 'r']\n",
    "\n",
    "        plt.subplot(\n",
    "            aspect=1, title=f'Percentage of tweets pro or against vaccination in {vaccine}\\nClassified {num_of_tweets_analyzed} tweets.')\n",
    "        type_show_ids = plt.pie(type_counts, labels=type_labels,\n",
    "                                autopct='%1.1f%%', shadow=True, colors=colors)\n",
    "        plt.savefig(f\"../visuals/{algo_short}/{vaccine}-{n_gram}.png\")\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_path = f\"../vectors/vectorizer_sentiment140_(1, 2)_1.pkl\"\n",
    "model_path = f\"../models/MultinomialNB_sentiment140_77_(1, 2).pkl\"\n",
    "tfidf = joblib.load(vectorizer_path)\n",
    "model = joblib.load(model_path)\n",
    "accs0 = []\n",
    "for lang in war:\n",
    "    df = pd.read_csv(f'../data/{lang}', delimiter=',')\n",
    "\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    df = df[['tweet', \"translate\", 'sentiment']]\n",
    "\n",
    "    if not lang == 'war.csv' and not lang == 'war2.csv':\n",
    "        df['tweet'] = df['translate']\n",
    "\n",
    "    print(df.head())\n",
    "    X = df.iloc[:, 0].fillna(' ')\n",
    "\n",
    "    tweets = X\n",
    "\n",
    "    num_of_tweets_analyzed = len(tweets)\n",
    "\n",
    "    y_pred = tfidf.transform(X)\n",
    "\n",
    "    predictions = model.predict(y_pred)\n",
    "    print(np.count_nonzero(predictions == 1), np.count_nonzero(predictions == 0))\n",
    "\n",
    "    # saving tweets to csv\n",
    "    tweets.to_csv(f'../analysis/tweets-{lang}.csv')\n",
    "    # saving sentiment predictions to csv\n",
    "    np.savetxt(f'../analysis/predictions-{lang}.csv',\n",
    "            predictions, delimiter=',', fmt=('%s'))\n",
    "\n",
    "    # adding sentiment column to the beginning\n",
    "    df = pd.read_csv(\n",
    "        f'../analysis/predictions-{lang}.csv', header=None)\n",
    "    df.rename(columns={0: 'sentiment'}, inplace=True)\n",
    "    # save to new csv file\n",
    "    df.to_csv(\n",
    "        f'../analysis/predictions-{lang}.csv', index=False)\n",
    "\n",
    "    # merging tweets and predictions\n",
    "    filenames = [f'../analysis/tweets-{lang}.csv',\n",
    "                f'../analysis/predictions-{lang}.csv']\n",
    "    dfs = []\n",
    "    for filename in filenames:\n",
    "        # read the csv, making sure the first two columns are str\n",
    "        df = pd.read_csv(filename, header=None, converters={0: str, 1: str})\n",
    "        # change the column names so they won't collide during concatenation\n",
    "        df.columns = [filename + str(cname) for cname in df.columns]\n",
    "        dfs.append(df)\n",
    "\n",
    "    # concatenate them horizontally\n",
    "    merged = pd.concat(dfs, axis=1)\n",
    "    # write it out\n",
    "    merged.to_csv(\n",
    "        f\"../analysis/merged-{lang}.csv\", header=None, index=None)\n",
    "\n",
    "    df = pd.read_csv(f'../analysis/merged-{lang}.csv')\n",
    "\n",
    "\n",
    "    title_type = df.groupby('sentiment').agg('count')\n",
    "\n",
    "    type_labels = ['positive', 'negative']\n",
    "    type_counts = title_type.tweet.sort_values()\n",
    "    accs0.append(type_counts)\n",
    "accs = np.array(accs0)\n",
    "f2 = lambda x: [round(x[0]/(x[0]+x[1])*100, 2), round(x[1]/(x[0]+x[1])*100, 2)]\n",
    "accs = [f2(x) for x in accs]\n",
    "accs\n",
    "# counts = [x[0]+x[1] for x in accs0]\n",
    "# counts\n",
    "langs = [\"french\", \"german\", \"italian\", \"norwegian\", \"polish\", \"russian\", \"spanish\", \"english\"]\n",
    "# plt.bar(langs, counts)\n",
    "# plt.show()\n",
    "    \n",
    "from cycler import cycler\n",
    "\n",
    "plt.figure()\n",
    "fig, ax = plt.subplots()\n",
    "plt.xticks(rotation=90)\n",
    "print(accs)\n",
    "plt.rc('axes', prop_cycle=(cycler('color', ['g', 'r'])))\n",
    "ax.plot(langs, accs, ls='-', marker='o', label=['Positive', 'Negative'])  \n",
    "\n",
    "plt.xlabel(\"Language\")\n",
    "plt.ylabel(\"Percentage\")\n",
    "plt.title(f\"Positive and Negative Sentiment Across Languages with MultinomialNB\")\n",
    "ax.legend()\n",
    "plt.savefig(f\"../visuals/yayin/war.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_path = f\"../vectors/vectorizer_sentiment140_(1, 2)_1.pkl\"\n",
    "model_path = f\"../models/ComplementNB_sentiment140_76_(1, 2).pkl\"\n",
    "tfidf = joblib.load(vectorizer_path)\n",
    "model = joblib.load(model_path)\n",
    "accs0 = []\n",
    "for lang in war:\n",
    "    df = pd.read_csv(f'../data/{lang}', delimiter=',')\n",
    "\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    df = df[['tweet', \"translate\", 'sentiment']]\n",
    "\n",
    "    if not lang == 'war.csv' and not lang == 'war2.csv':\n",
    "        df['tweet'] = df['translate']\n",
    "\n",
    "    print(df.head())\n",
    "    X = df.iloc[:, 0].fillna(' ')\n",
    "\n",
    "    tweets = X\n",
    "\n",
    "    num_of_tweets_analyzed = len(tweets)\n",
    "\n",
    "    y_pred = tfidf.transform(X)\n",
    "\n",
    "    predictions = model.predict(y_pred)\n",
    "    print(np.count_nonzero(predictions == 1), np.count_nonzero(predictions == 0))\n",
    "\n",
    "    # saving tweets to csv\n",
    "    tweets.to_csv(f'../analysis/tweets-{lang}.csv')\n",
    "    # saving sentiment predictions to csv\n",
    "    np.savetxt(f'../analysis/predictions-{lang}.csv',\n",
    "            predictions, delimiter=',', fmt=('%s'))\n",
    "\n",
    "    # adding sentiment column to the beginning\n",
    "    df = pd.read_csv(\n",
    "        f'../analysis/predictions-{lang}.csv', header=None)\n",
    "    df.rename(columns={0: 'sentiment'}, inplace=True)\n",
    "    # save to new csv file\n",
    "    df.to_csv(\n",
    "        f'../analysis/predictions-{lang}.csv', index=False)\n",
    "\n",
    "    # merging tweets and predictions\n",
    "    filenames = [f'../analysis/tweets-{lang}.csv',\n",
    "                f'../analysis/predictions-{lang}.csv']\n",
    "    dfs = []\n",
    "    for filename in filenames:\n",
    "        # read the csv, making sure the first two columns are str\n",
    "        df = pd.read_csv(filename, header=None, converters={0: str, 1: str})\n",
    "        # change the column names so they won't collide during concatenation\n",
    "        df.columns = [filename + str(cname) for cname in df.columns]\n",
    "        dfs.append(df)\n",
    "\n",
    "    # concatenate them horizontally\n",
    "    merged = pd.concat(dfs, axis=1)\n",
    "    # write it out\n",
    "    merged.to_csv(\n",
    "        f\"../analysis/merged-{lang}.csv\", header=None, index=None)\n",
    "\n",
    "    df = pd.read_csv(f'../analysis/merged-{lang}.csv')\n",
    "\n",
    "\n",
    "    title_type = df.groupby('sentiment').agg('count')\n",
    "\n",
    "    type_labels = ['positive', 'negative']\n",
    "    type_counts = title_type.tweet.sort_values()\n",
    "    accs0.append(type_counts)\n",
    "accs = np.array(accs0)\n",
    "f2 = lambda x: [round(x[0]/(x[0]+x[1])*100, 2), round(x[1]/(x[0]+x[1])*100, 2)]\n",
    "accs = [f2(x) for x in accs]\n",
    "accs\n",
    "# counts = [x[0]+x[1] for x in accs0]\n",
    "# counts\n",
    "langs = [\"french\", \"german\", \"italian\", \"norwegian\", \"polish\", \"russian\", \"spanish\", \"english\"]\n",
    "# plt.bar(langs, counts)\n",
    "# plt.show()\n",
    "    \n",
    "from cycler import cycler\n",
    "\n",
    "plt.figure()\n",
    "fig, ax = plt.subplots()\n",
    "plt.xticks(rotation=90)\n",
    "print(accs)\n",
    "plt.rc('axes', prop_cycle=(cycler('color', ['g', 'r'])))\n",
    "ax.plot(langs, accs, ls='-', marker='o', label=['Positive', 'Negative'])  \n",
    "\n",
    "plt.xlabel(\"Language\")\n",
    "plt.ylabel(\"Percentage\")\n",
    "plt.title(f\"Positive and Negative Sentiment Across Languages with ComplementNB\")\n",
    "ax.legend()\n",
    "plt.savefig(f\"../visuals/yayin/war.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f595b24bd0005ade19c9cc9195ebfd43399e9f8b470abdede700a27b5c9ee90b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
