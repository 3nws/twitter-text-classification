{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.preprocessing.text import tokenizer_from_json\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "dataset_dir = 'sentiment140'\n",
    "# dataset_dir = 'imdb'\n",
    "# dataset_dir = 'coronaNLP'\n",
    "\n",
    "vaccines = [\"biontech\", \"janssen\", \"moderna\",\n",
    "            \"oxford\", \"sinopharm\", \"sinovac\", \"sputnik\"]\n",
    "\n",
    "\n",
    "years = [\"2020\", \"2021\", \"2022\"]\n",
    "months = [\"january\", \"february\", \"march\", \"april\", \"may\", \"june\",\n",
    "          \"july\", \"august\", \"september\", \"october\", \"november\", \"december\"]\n",
    "\n",
    "\n",
    "for year in years:\n",
    "    for month in months:\n",
    "        models_dir = '../models/NN_model_seven_12008898266757515530_0.7899888157844543'\n",
    "        tokenizers_dir = '../tokenizers/12008898266757515530.pkl'\n",
    "\n",
    "        # already processed\n",
    "        try:\n",
    "            df = pd.read_csv(f'../{year}-data/covid-{month}.csv', delimiter=',')\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        df = df.drop_duplicates()\n",
    "\n",
    "        df = df[['tweet', 'sentiment']]\n",
    "\n",
    "        df.head()\n",
    "        model = load_model(models_dir)\n",
    "        model.summary()\n",
    "        tokenizer = joblib.load(tokenizers_dir)\n",
    "        word_index = tokenizer.word_index\n",
    "\n",
    "        X = df.iloc[:, 0].fillna(' ')\n",
    "\n",
    "        tweets = X\n",
    "\n",
    "        num_of_tweets_analyzed = len(tweets)\n",
    "\n",
    "        sequences = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "\n",
    "        # Max number of words in a sequence\n",
    "        max_length = 37\n",
    "\n",
    "        padded = pad_sequences(\n",
    "            sequences, maxlen=max_length, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "        # Check reversing the indices\n",
    "\n",
    "        # flip (key, value)\n",
    "        reverse_word_index = dict([(idx, word) for (word, idx) in word_index.items()])\n",
    "\n",
    "        def decode(sequence):\n",
    "            return \" \".join([reverse_word_index.get(idx, \"?\") for idx in sequence])\n",
    "\n",
    "        predictions = model.predict(padded)\n",
    "\n",
    "        # Only for BinaryCrossentropy\n",
    "        predictions = [1 if p > 0.5 else 0 for p in predictions]\n",
    "\n",
    "        # saving tweets to csv\n",
    "        tweets.to_csv(f'../analysis/tweets-{month}-{year}.csv')\n",
    "        # saving sentiment predictions to csv\n",
    "        np.savetxt(f'../analysis/predictions-{month}-{year}.csv',\n",
    "                   predictions, delimiter=',', fmt=('%s'))\n",
    "\n",
    "        # adding sentiment column to the beginning\n",
    "        df = pd.read_csv(\n",
    "            f'../analysis/predictions-{month}-{year}.csv', header=None)\n",
    "        df.rename(columns={0: 'sentiment'}, inplace=True)\n",
    "        # save to new csv file\n",
    "        df.to_csv(\n",
    "             f'../analysis/predictions-{month}-{year}.csv', index=False)\n",
    "\n",
    "        # merging tweets and predictions\n",
    "        filenames = [f'../analysis/tweets-{month}-{year}.csv',\n",
    "                       f'../analysis/predictions-{month}-{year}.csv']\n",
    "        dfs = []\n",
    "        for filename in filenames:\n",
    "            # read the csv, making sure the first two columns are str\n",
    "            df = pd.read_csv(filename, header=None,\n",
    "                             converters={0: str, 1: str})\n",
    "            # change the column names so they won't collide during concatenation\n",
    "            df.columns = [filename + str(cname) for cname in df.columns]\n",
    "            dfs.append(df)\n",
    "\n",
    "        # concatenate them horizontally\n",
    "        merged = pd.concat(dfs, axis=1)\n",
    "        # write it out\n",
    "        merged.to_csv(\n",
    "            f\"../analysis/merged-{month}-{year}.csv\", header=None, index=None)\n",
    "\n",
    "        df = pd.read_csv(f'../analysis/merged-{month}-{year}.csv')\n",
    "\n",
    "        labels = ['negative', 'positive']\n",
    "\n",
    "        title_type = df.groupby('sentiment').agg('count')\n",
    "\n",
    "        type_labels = ['positive', 'negative']\n",
    "        type_counts = title_type.tweet.sort_values()\n",
    "\n",
    "        colors = ['g', 'r']\n",
    "\n",
    "        plt.subplot(\n",
    "            aspect=1, title=f'Percentage of tweets pro or against vaccination in {month.capitalize()} {year}\\nClassified {num_of_tweets_analyzed} tweets.')\n",
    "        type_show_ids = plt.pie(type_counts, labels=type_labels,\n",
    "                                autopct='%1.1f%%', shadow=True, colors=colors)\n",
    "        plt.savefig(f\"../visuals/{month}-{year}.png\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for vaccine in vaccines:\n",
    "    models_dir = '../models/NN_model_seven_12008898266757515530_0.7899888157844543'\n",
    "    tokenizers_dir = '../tokenizers/12008898266757515530.pkl'\n",
    "    # already processed\n",
    "    df = pd.read_csv(f'../vaccines/{vaccine}.csv', delimiter=',')\n",
    "    df = df.drop_duplicates()\n",
    "    df = df[['tweet', 'sentiment']]\n",
    "    model = load_model(models_dir)\n",
    "    model.summary()\n",
    "    tokenizer = joblib.load(tokenizers_dir)\n",
    "    word_index = tokenizer.word_index\n",
    "\n",
    "    X = df.iloc[:, 0].fillna(' ')\n",
    "\n",
    "    tweets = X\n",
    "\n",
    "    num_of_tweets_analyzed = len(tweets)\n",
    "\n",
    "    sequences = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "    # Max number of words in a sequence\n",
    "    max_length = 37\n",
    "\n",
    "    padded = pad_sequences(\n",
    "          sequences, maxlen=max_length, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "    # Check reversing the indices\n",
    "\n",
    "    # flip (key, value)\n",
    "    reverse_word_index = dict([(idx, word)\n",
    "                                  for (word, idx) in word_index.items()])\n",
    "\n",
    "    def decode(sequence):\n",
    "        return \" \".join([reverse_word_index.get(idx, \"?\") for idx in sequence])\n",
    "\n",
    "    predictions = model.predict(padded)\n",
    "\n",
    "    # Only for BinaryCrossentropy\n",
    "    predictions = [1 if p > 0.5 else 0 for p in predictions]\n",
    "    # saving tweets to csv\n",
    "    tweets.to_csv(f'../analysis/tweets-{vaccine}.csv')\n",
    "    # saving sentiment predictions to csv\n",
    "    np.savetxt(f'../analysis/predictions-{vaccine}.csv',\n",
    "               predictions, delimiter=',', fmt=('%s'))\n",
    "    # adding sentiment column to the beginning\n",
    "    df = pd.read_csv(\n",
    "        f'../analysis/predictions-{vaccine}.csv', header=None)\n",
    "    df.rename(columns={0: 'sentiment'}, inplace=True)\n",
    "    # save to new csv file\n",
    "    df.to_csv(\n",
    "         f'../analysis/predictions-{vaccine}.csv', index=False)\n",
    "    # merging tweets and predictions\n",
    "    filenames = [f'../analysis/tweets-{vaccine}.csv',\n",
    "                   f'../analysis/predictions-{vaccine}.csv']\n",
    "    dfs = []\n",
    "    for filename in filenames:\n",
    "        # read the csv, making sure the first two columns are str\n",
    "        df = pd.read_csv(filename, header=None,\n",
    "                         converters={0: str, 1: str})\n",
    "        # change the column names so they won't collide during concatenation\n",
    "        df.columns = [filename + str(cname) for cname in df.columns]\n",
    "        dfs.append(df)\n",
    "    # concatenate them horizontally\n",
    "    merged = pd.concat(dfs, axis=1)\n",
    "    # write it out\n",
    "    merged.to_csv(\n",
    "        f\"../analysis/merged-{vaccine}.csv\", header=None, index=None)\n",
    "    df = pd.read_csv(f'../analysis/merged-{vaccine}.csv')\n",
    "    labels = ['negative', 'positive']\n",
    "    title_type = df.groupby('sentiment').agg('count')\n",
    "    type_labels = ['positive', 'negative']\n",
    "    type_counts = title_type.tweet.sort_values()\n",
    "    colors = ['g', 'r']\n",
    "    plt.subplot(\n",
    "        aspect=1, title=f'Percentage of tweets pro or against vaccination in {month.capitalize()} {year}\\nClassified {num_of_tweets_analyzed} tweets.')\n",
    "    type_show_ids = plt.pie(type_counts, labels=type_labels,\n",
    "                            autopct='%1.1f%%', shadow=True, colors=colors)\n",
    "    plt.savefig(f\"../visuals/{vaccine}.png\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "599e51aa143538ccec1c7ab4b528efe64565e20e387dbc49eb00bf436cfb223b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
