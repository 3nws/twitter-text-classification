{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.preprocessing.text import tokenizer_from_json\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "dataset_dir = 'sentiment140'\n",
    "# dataset_dir = 'imdb'\n",
    "# dataset_dir = 'coronaNLP'\n",
    "\n",
    "vaccines = [\"biontech\", \"janssen\", \"moderna\",\n",
    "            \"oxford\", \"sinopharm\", \"sinovac\", \"sputnik\"]\n",
    "\n",
    "\n",
    "\n",
    "years = [\"2020\", \"2021\", \"2022\"]\n",
    "months = [\"january\", \"february\", \"march\", \"april\", \"may\", \"june\",\n",
    "          \"july\", \"august\", \"september\", \"october\", \"november\", \"december\"]\n",
    "\n",
    "\n",
    "## MONTHS\n",
    "# models_dir = '../models/NN_model_seven_12008898266757515530_0.7899888157844543'\n",
    "# tokenizers_dir = '../tokenizers/12008898266757515530.pkl'\n",
    "# model = load_model(models_dir)\n",
    "# model.summary()\n",
    "# tokenizer = joblib.load(tokenizers_dir)\n",
    "# word_index = tokenizer.word_index\n",
    "# for year in years:\n",
    "#     for month in months:\n",
    "    \n",
    "#         # already processed\n",
    "#         try:\n",
    "#             df = pd.read_csv(f'../{year}-data/covid-{month}.csv', delimiter=',')\n",
    "#         except Exception:\n",
    "#             continue\n",
    "\n",
    "#         df = df.drop_duplicates()\n",
    "\n",
    "#         df = df[['tweet', 'sentiment']]\n",
    "\n",
    "#         df.head()\n",
    "        \n",
    "\n",
    "#         X = df.iloc[:, 0].fillna(' ')\n",
    "\n",
    "#         tweets = X\n",
    "\n",
    "#         num_of_tweets_analyzed = len(tweets)\n",
    "\n",
    "#         sequences = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "\n",
    "#         # Max number of words in a sequence\n",
    "#         max_length = 37\n",
    "\n",
    "#         padded = pad_sequences(\n",
    "#             sequences, maxlen=max_length, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "#         # Check reversing the indices\n",
    "\n",
    "#         # flip (key, value)\n",
    "#         reverse_word_index = dict([(idx, word) for (word, idx) in word_index.items()])\n",
    "\n",
    "#         def decode(sequence):\n",
    "#             return \" \".join([reverse_word_index.get(idx, \"?\") for idx in sequence])\n",
    "\n",
    "#         predictions = model.predict(padded)\n",
    "\n",
    "#         # Only for BinaryCrossentropy\n",
    "#         predictions = [1 if p > 0.5 else 0 for p in predictions]\n",
    "\n",
    "#         # saving tweets to csv\n",
    "#         tweets.to_csv(f'../analysis/tweets-{month}-{year}.csv')\n",
    "#         # saving sentiment predictions to csv\n",
    "#         np.savetxt(f'../analysis/predictions-{month}-{year}.csv',\n",
    "#                    predictions, delimiter=',', fmt=('%s'))\n",
    "\n",
    "#         # adding sentiment column to the beginning\n",
    "#         df = pd.read_csv(\n",
    "#             f'../analysis/predictions-{month}-{year}.csv', header=None)\n",
    "#         df.rename(columns={0: 'sentiment'}, inplace=True)\n",
    "#         # save to new csv file\n",
    "#         df.to_csv(\n",
    "#              f'../analysis/predictions-{month}-{year}.csv', index=False)\n",
    "\n",
    "#         # merging tweets and predictions\n",
    "#         filenames = [f'../analysis/tweets-{month}-{year}.csv',\n",
    "#                        f'../analysis/predictions-{month}-{year}.csv']\n",
    "#         dfs = []\n",
    "#         for filename in filenames:\n",
    "#             # read the csv, making sure the first two columns are str\n",
    "#             df = pd.read_csv(filename, header=None,\n",
    "#                              converters={0: str, 1: str})\n",
    "#             # change the column names so they won't collide during concatenation\n",
    "#             df.columns = [filename + str(cname) for cname in df.columns]\n",
    "#             dfs.append(df)\n",
    "\n",
    "#         # concatenate them horizontally\n",
    "#         merged = pd.concat(dfs, axis=1)\n",
    "#         # write it out\n",
    "#         merged.to_csv(\n",
    "#             f\"../analysis/merged-{month}-{year}.csv\", header=None, index=None)\n",
    "\n",
    "#         df = pd.read_csv(f'../analysis/merged-{month}-{year}.csv')\n",
    "\n",
    "#         labels = ['negative', 'positive']\n",
    "\n",
    "#         title_type = df.groupby('sentiment').agg('count')\n",
    "\n",
    "#         type_labels = ['positive', 'negative']\n",
    "#         type_counts = title_type.tweet.sort_values()\n",
    "\n",
    "#         colors = ['g', 'r']\n",
    "\n",
    "#         plt.subplot(\n",
    "#             aspect=1, title=f'Percentage of tweets pro or against vaccination in {month.capitalize()} {year}\\nClassified {num_of_tweets_analyzed} tweets.')\n",
    "#         type_show_ids = plt.pie(type_counts, labels=type_labels,\n",
    "#                                 autopct='%1.1f%%', shadow=True, colors=colors)\n",
    "#         plt.savefig(f\"../visuals/{month}-{year}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## WAR!!\n",
    "war = []\n",
    "\n",
    "for file in os.listdir(\"../data/\"):\n",
    "    war.append(file)\n",
    "    \n",
    "\n",
    "models_dir = '../models/NN_model_seven_12008898266757515530_0.7899888157844543'\n",
    "tokenizers_dir = '../tokenizers/12008898266757515530.pkl'\n",
    "model = load_model(models_dir)\n",
    "model.summary()\n",
    "tokenizer = joblib.load(tokenizers_dir)\n",
    "word_index = tokenizer.word_index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs0 = []\n",
    "\n",
    "for lang in war:\n",
    "    print(lang)\n",
    "    # already processed\n",
    "    df = pd.read_csv(f'../data/{lang}', delimiter=',')\n",
    "    df = df.drop_duplicates()\n",
    "    df = df[['tweet', 'translate', 'sentiment']]\n",
    "    if not lang == 'war.csv' and not lang == 'war2.csv':\n",
    "        df['tweet'] = df['translate']\n",
    "\n",
    "    X = df.iloc[:, 0].fillna(' ')\n",
    "\n",
    "    tweets = X\n",
    "\n",
    "    num_of_tweets_analyzed = len(tweets)\n",
    "\n",
    "    sequences = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "    # Max number of words in a sequence\n",
    "    max_length = 37\n",
    "\n",
    "    padded = pad_sequences(\n",
    "        sequences, maxlen=max_length, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "    # Check reversing the indices\n",
    "\n",
    "    # flip (key, value)\n",
    "    reverse_word_index = dict([(idx, word)\n",
    "                                for (word, idx) in word_index.items()])\n",
    "\n",
    "\n",
    "    predictions = model.predict(padded)\n",
    "    \n",
    "    # Only for BinaryCrossentropy\n",
    "    predictions = np.array([1 if p > 0.5 else 0 for p in predictions])\n",
    "    print(np.count_nonzero(predictions == 1), np.count_nonzero(predictions == 0))\n",
    "    \n",
    "    # saving tweets to csv\n",
    "    tweets.to_csv(f'../analysis/tweets-{lang}.csv')\n",
    "    # saving sentiment predictions to csv\n",
    "    np.savetxt(f'../analysis/predictions-{lang}.csv',\n",
    "            predictions, delimiter=',', fmt=('%s'))\n",
    "    # adding sentiment column to the beginning\n",
    "    df = pd.read_csv(\n",
    "        f'../analysis/predictions-{lang}.csv', header=None)\n",
    "    df.rename(columns={0: 'sentiment'}, inplace=True)\n",
    "    # save to new csv file\n",
    "    df.to_csv(\n",
    "        f'../analysis/predictions-{lang}.csv', index=False)\n",
    "    # merging tweets and predictions\n",
    "    filenames = [f'../analysis/tweets-{lang}.csv',\n",
    "                f'../analysis/predictions-{lang}.csv']\n",
    "    dfs = []\n",
    "    for filename in filenames:\n",
    "        # read the csv, making sure the first two columns are str\n",
    "        df = pd.read_csv(filename, header=None,\n",
    "                        converters={0: str, 1: str})\n",
    "        # change the column names so they won't collide during concatenation\n",
    "        df.columns = [filename + str(cname) for cname in df.columns]\n",
    "        dfs.append(df)\n",
    "    # concatenate them horizontally\n",
    "    merged = pd.concat(dfs, axis=1)\n",
    "    # write it out\n",
    "    merged.to_csv(\n",
    "        f\"../analysis/merged-{lang}.csv\", header=None, index=None)\n",
    "    df = pd.read_csv(f'../analysis/merged-{lang}.csv')\n",
    "    title_type = df.groupby('sentiment').agg('count')\n",
    "    type_labels = ['positive', 'negative']\n",
    "    type_counts = title_type.tweet.sort_values()\n",
    "    accs0.append(type_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = np.array(accs0)\n",
    "f2 = lambda x: [round(x[0]/(x[0]+x[1]), 2), round(x[1]/(x[0]+x[1]), 2)]\n",
    "accs = [f2(x) for x in accs][:-1]\n",
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = [\"czech\", \"french\", \"german\", \"italian\", \"norwegian\", \"polish\", \"russian\", \"spanish\", \"sweding\", \"english\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cycler import cycler\n",
    "\n",
    "plt.figure()\n",
    "fig, ax = plt.subplots()\n",
    "plt.xticks(rotation=90)\n",
    "plt.rc('axes', prop_cycle=(cycler('color', ['g', 'r'])))\n",
    "ax.plot(langs, accs, ls='-', marker='o', label=['Positive', 'Negative'])  \n",
    "\n",
    "plt.xlabel(\"Language\")\n",
    "plt.ylabel(\"Percentage\")\n",
    "plt.title(\"Positive and Negative Sentiment Across Languages with Bi-LSTM\")\n",
    "ax.legend()\n",
    "plt.savefig(f\"../visuals/rnn/war.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## VACCINES\n",
    "# models_dir = '../models/NN_model_seven_12008898266757515530_0.7899888157844543'\n",
    "# tokenizers_dir = '../tokenizers/12008898266757515530.pkl'\n",
    "# model = load_model(models_dir)\n",
    "# model.summary()\n",
    "# tokenizer = joblib.load(tokenizers_dir)\n",
    "# word_index = tokenizer.word_index\n",
    "# for vaccine in vaccines:\n",
    "    \n",
    "    \n",
    "#     # already processed\n",
    "#     df = pd.read_csv(f'../vaccines/{vaccine}.csv', delimiter=',')\n",
    "#     df = df.drop_duplicates()\n",
    "#     df = df[['tweet', 'sentiment']]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "#     X = df.iloc[:, 0].fillna(' ')\n",
    "\n",
    "#     tweets = X\n",
    "\n",
    "#     num_of_tweets_analyzed = len(tweets)\n",
    "\n",
    "#     sequences = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "#     # Max number of words in a sequence\n",
    "#     max_length = 37\n",
    "\n",
    "#     padded = pad_sequences(\n",
    "#           sequences, maxlen=max_length, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "#     # Check reversing the indices\n",
    "\n",
    "#     # flip (key, value)\n",
    "#     reverse_word_index = dict([(idx, word)\n",
    "#                                   for (word, idx) in word_index.items()])\n",
    "\n",
    "#     def decode(sequence):\n",
    "#         return \" \".join([reverse_word_index.get(idx, \"?\") for idx in sequence])\n",
    "\n",
    "#     predictions = model.predict(padded)\n",
    "\n",
    "#     # Only for BinaryCrossentropy\n",
    "#     predictions = [1 if p > 0.5 else 0 for p in predictions]\n",
    "#     # saving tweets to csv\n",
    "#     tweets.to_csv(f'../analysis/tweets-{vaccine}.csv')\n",
    "#     # saving sentiment predictions to csv\n",
    "#     np.savetxt(f'../analysis/predictions-{vaccine}.csv',\n",
    "#                predictions, delimiter=',', fmt=('%s'))\n",
    "#     # adding sentiment column to the beginning\n",
    "#     df = pd.read_csv(\n",
    "#         f'../analysis/predictions-{vaccine}.csv', header=None)\n",
    "#     df.rename(columns={0: 'sentiment'}, inplace=True)\n",
    "#     # save to new csv file\n",
    "#     df.to_csv(\n",
    "#          f'../analysis/predictions-{vaccine}.csv', index=False)\n",
    "#     # merging tweets and predictions\n",
    "#     filenames = [f'../analysis/tweets-{vaccine}.csv',\n",
    "#                    f'../analysis/predictions-{vaccine}.csv']\n",
    "#     dfs = []\n",
    "#     for filename in filenames:\n",
    "#         # read the csv, making sure the first two columns are str\n",
    "#         df = pd.read_csv(filename, header=None,\n",
    "#                          converters={0: str, 1: str})\n",
    "#         # change the column names so they won't collide during concatenation\n",
    "#         df.columns = [filename + str(cname) for cname in df.columns]\n",
    "#         dfs.append(df)\n",
    "#     # concatenate them horizontally\n",
    "#     merged = pd.concat(dfs, axis=1)\n",
    "#     # write it out\n",
    "#     merged.to_csv(\n",
    "#         f\"../analysis/merged-{vaccine}.csv\", header=None, index=None)\n",
    "#     df = pd.read_csv(f'../analysis/merged-{vaccine}.csv')\n",
    "#     labels = ['negative', 'positive']\n",
    "#     title_type = df.groupby('sentiment').agg('count')\n",
    "#     type_labels = ['positive', 'negative']\n",
    "#     type_counts = title_type.tweet.sort_values()\n",
    "#     colors = ['g', 'r']\n",
    "#     plt.subplot(\n",
    "#         aspect=1, title=f'Percentage of tweets pro or against vaccines branded by {vaccine}\\nClassified {num_of_tweets_analyzed} tweets.')\n",
    "#     type_show_ids = plt.pie(type_counts, labels=type_labels,\n",
    "#                             autopct='%1.1f%%', shadow=True, colors=colors)\n",
    "#     plt.savefig(f\"../visuals/{vaccine}.png\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f595b24bd0005ade19c9cc9195ebfd43399e9f8b470abdede700a27b5c9ee90b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
