{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embeddinglayer (Embedding)  (None, 37, 64)            3200000   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 37, 64)           24832     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 64)               24832     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,251,777\n",
      "Trainable params: 3,251,777\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.preprocessing.text import tokenizer_from_json\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "dataset_dir = 'sentiment140'\n",
    "# dataset_dir = 'imdb'\n",
    "# dataset_dir = 'coronaNLP'\n",
    "\n",
    "# vaccines = [\"biontech\", \"janssen\", \"moderna\",\n",
    "#             \"oxford\", \"sinopharm\", \"sinovac\", \"sputnik\"]\n",
    "\n",
    "\n",
    "\n",
    "# years = [\"2020\", \"2021\", \"2022\"]\n",
    "# months = [\"january\", \"february\", \"march\", \"april\", \"may\", \"june\",\n",
    "#           \"july\", \"august\", \"september\", \"october\", \"november\", \"december\"]\n",
    "# models_dir = '../models/NN_model_seven_12008898266757515530_0.7899888157844543'\n",
    "# tokenizers_dir = '../tokenizers/12008898266757515530.pkl'\n",
    "# model = load_model(models_dir)\n",
    "# model.summary()\n",
    "# tokenizer = joblib.load(tokenizers_dir)\n",
    "# word_index = tokenizer.word_index\n",
    "# for year in years:\n",
    "#     for month in months:\n",
    "#         \n",
    "#         \n",
    "\n",
    "#         # already processed\n",
    "#         try:\n",
    "#             df = pd.read_csv(f'../{year}-data/covid-{month}.csv', delimiter=',')\n",
    "#         except Exception:\n",
    "#             continue\n",
    "\n",
    "#         df = df.drop_duplicates()\n",
    "\n",
    "#         df = df[['tweet', 'sentiment']]\n",
    "\n",
    "#         df.head()\n",
    "#         \n",
    "#         \n",
    "#         \n",
    "#         \n",
    "\n",
    "#         X = df.iloc[:, 0].fillna(' ')\n",
    "\n",
    "#         tweets = X\n",
    "\n",
    "#         num_of_tweets_analyzed = len(tweets)\n",
    "\n",
    "#         sequences = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "\n",
    "#         # Max number of words in a sequence\n",
    "#         max_length = 37\n",
    "\n",
    "#         padded = pad_sequences(\n",
    "#             sequences, maxlen=max_length, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "#         # Check reversing the indices\n",
    "\n",
    "#         # flip (key, value)\n",
    "#         reverse_word_index = dict([(idx, word) for (word, idx) in word_index.items()])\n",
    "\n",
    "#         def decode(sequence):\n",
    "#             return \" \".join([reverse_word_index.get(idx, \"?\") for idx in sequence])\n",
    "\n",
    "#         predictions = model.predict(padded)\n",
    "\n",
    "#         # Only for BinaryCrossentropy\n",
    "#         predictions = [1 if p > 0.5 else 0 for p in predictions]\n",
    "\n",
    "#         # saving tweets to csv\n",
    "#         tweets.to_csv(f'../analysis/tweets-{month}-{year}.csv')\n",
    "#         # saving sentiment predictions to csv\n",
    "#         np.savetxt(f'../analysis/predictions-{month}-{year}.csv',\n",
    "#                    predictions, delimiter=',', fmt=('%s'))\n",
    "\n",
    "#         # adding sentiment column to the beginning\n",
    "#         df = pd.read_csv(\n",
    "#             f'../analysis/predictions-{month}-{year}.csv', header=None)\n",
    "#         df.rename(columns={0: 'sentiment'}, inplace=True)\n",
    "#         # save to new csv file\n",
    "#         df.to_csv(\n",
    "#              f'../analysis/predictions-{month}-{year}.csv', index=False)\n",
    "\n",
    "#         # merging tweets and predictions\n",
    "#         filenames = [f'../analysis/tweets-{month}-{year}.csv',\n",
    "#                        f'../analysis/predictions-{month}-{year}.csv']\n",
    "#         dfs = []\n",
    "#         for filename in filenames:\n",
    "#             # read the csv, making sure the first two columns are str\n",
    "#             df = pd.read_csv(filename, header=None,\n",
    "#                              converters={0: str, 1: str})\n",
    "#             # change the column names so they won't collide during concatenation\n",
    "#             df.columns = [filename + str(cname) for cname in df.columns]\n",
    "#             dfs.append(df)\n",
    "\n",
    "#         # concatenate them horizontally\n",
    "#         merged = pd.concat(dfs, axis=1)\n",
    "#         # write it out\n",
    "#         merged.to_csv(\n",
    "#             f\"../analysis/merged-{month}-{year}.csv\", header=None, index=None)\n",
    "\n",
    "#         df = pd.read_csv(f'../analysis/merged-{month}-{year}.csv')\n",
    "\n",
    "#         labels = ['negative', 'positive']\n",
    "\n",
    "#         title_type = df.groupby('sentiment').agg('count')\n",
    "\n",
    "#         type_labels = ['positive', 'negative']\n",
    "#         type_counts = title_type.tweet.sort_values()\n",
    "\n",
    "#         colors = ['g', 'r']\n",
    "\n",
    "#         plt.subplot(\n",
    "#             aspect=1, title=f'Percentage of tweets pro or against vaccination in {month.capitalize()} {year}\\nClassified {num_of_tweets_analyzed} tweets.')\n",
    "#         type_show_ids = plt.pie(type_counts, labels=type_labels,\n",
    "#                                 autopct='%1.1f%%', shadow=True, colors=colors)\n",
    "#         plt.savefig(f\"../visuals/{month}-{year}.png\")\n",
    "\n",
    "\n",
    "\n",
    "war = []\n",
    "\n",
    "for file in os.listdir(\"../data/\"):\n",
    "    war.append(file)\n",
    "    \n",
    "\n",
    "models_dir = '../models/NN_model_seven_12008898266757515530_0.7899888157844543'\n",
    "tokenizers_dir = '../tokenizers/12008898266757515530.pkl'\n",
    "model = load_model(models_dir)\n",
    "model.summary()\n",
    "tokenizer = joblib.load(tokenizers_dir)\n",
    "word_index = tokenizer.word_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "war-czech.csv\n",
      "                                               tweet  sentiment\n",
      "0  Martin arrive after returning from Ukraine thi...          2\n",
      "1  SIK99 is Taki stupid most of today's Ukrainian...          2\n",
      "2  If Russia stops fighting the war will end the ...          2\n",
      "3  Listi I have understood the argumentation of d...          2\n",
      "4  Blog e Fiala Another great thing is how Putin ...          2\n",
      "war-french.csv\n",
      "                                               tweet  sentiment\n",
      "0  Biden sends Venezuela to obtain oil president ...          2\n",
      "1  To believe that Lukrain leads by procur a war ...          2\n",
      "2  Direct - Guerr in Ukrain read increases his ai...          2\n",
      "3  On February 24, Vladimir Poutin lacs a contain...          2\n",
      "4  This is what the Westerners want to push Russi...          2\n",
      "war-german.csv\n",
      "                                               tweet  sentiment\n",
      "0  83 RUS Russia un Ulyanov osc eu Mitru 2âƒ£ The U...          2\n",
      "1  The error is marked yellow voelkerrecht un Cha...          2\n",
      "2  Tom9999 Press Club I don't find at all because...          2\n",
      "3  E 24 February 2022, Russia began a large -scal...          2\n",
      "4  According to international law of Ukrain, the ...          2\n",
      "war-italian.csv\n",
      "                                               tweet  sentiment\n",
      "0  Three months of Ukrainian Russia War brought a...          2\n",
      "1  soldiers of the Ukrainian regular army self -d...          2\n",
      "2  The Ukrainian army does its job like the Russi...          2\n",
      "3  As the largest Ukrainian novelist is fighting ...          2\n",
      "4  Sorry I am the only one who has never seen the...          2\n",
      "war-norwegian.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:asyncio:Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x000002633DB35438>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet  sentiment\n",
      "0  Is not a war profit we sell Ingent to Russia a...          2\n",
      "1  Ukraine has moved the court of European democr...          2\n",
      "2  I see full of those around the world know some...          2\n",
      "3  Doria Russia Soviet has just fine invades coun...          2\n",
      "4  Red does not know what a safety guarantee is t...          2\n",
      "war-polish.csv\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object NoneType can't be used in 'await' expression",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Enes\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\async_google_trans_new\\main.py\u001b[0m in \u001b[0;36mtranslate\u001b[1;34m(self, text, lang_tgt, lang_src, pronounce)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m                 \u001b[1;32masync\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m                     \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mawait\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Enes\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\aiohttp\\client.py\u001b[0m in \u001b[0;36m__aenter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1116\u001b[0m     \u001b[1;32masync\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m__aenter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0m_RetType\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1117\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_resp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_coro\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1118\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_resp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Enes\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\aiohttp\\client.py\u001b[0m in \u001b[0;36m_request\u001b[1;34m(self, method, str_or_url, params, data, json, cookies, headers, skip_auto_headers, auth, allow_redirects, max_redirects, compress, chunked, expect100, raise_for_status, read_until_eof, proxy, proxy_auth, timeout, verify_ssl, fingerprint, ssl_context, ssl, proxy_headers, trace_request_ctx, read_bufsize)\u001b[0m\n\u001b[0;32m    543\u001b[0m                             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 544\u001b[1;33m                                 \u001b[1;32mawait\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    545\u001b[0m                             \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Enes\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\aiohttp\\client_reqrep.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self, connection)\u001b[0m\n\u001b[0;32m    889\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 890\u001b[1;33m                     \u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpayload\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_protocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    891\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mhttp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHttpProcessingError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Enes\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\aiohttp\\streams.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    603\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 604\u001b[1;33m                 \u001b[1;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_waiter\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    605\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0masyncio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCancelledError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0masyncio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTimeoutError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mCancelledError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4068/1765418565.py\u001b[0m in \u001b[0;36masync-def-wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4068/1765418565.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mtweets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4068/1765418565.py\u001b[0m in \u001b[0;36mtranslate\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;34m\" \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[1;31m# df['tweet'] = df['tweet'].apply(translate)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tweet'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mawait\u001b[0m \u001b[0masyncio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tweet'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Enes\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\async_google_trans_new\\main.py\u001b[0m in \u001b[0;36mtranslate\u001b[1;34m(self, text, lang_tgt, lang_src, pronounce)\u001b[0m\n\u001b[0;32m    241\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTransError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m             \u001b[1;32mawait\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    244\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object NoneType can't be used in 'await' expression"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import async_google_trans_new\n",
    "import asyncio\n",
    "\n",
    "\n",
    "async def main():\n",
    "    g = async_google_trans_new.AsyncTranslator()\n",
    "    for lang in war:\n",
    "        print(lang)\n",
    "        # already processed\n",
    "        df = pd.read_csv(f'../data/{lang}', delimiter=',')\n",
    "        df = df.drop_duplicates()\n",
    "        df = df[['tweet', 'sentiment']]\n",
    "        async def translate(text):\n",
    "            if text is not None:\n",
    "                return await g.translate(text, \"en\")\n",
    "            return \" \"\n",
    "        \n",
    "        # df['tweet'] = df['tweet'].apply(translate)\n",
    "        df['tweet'] = await asyncio.gather(*[translate(text) for text in df['tweet']])\n",
    "        print(df.head())\n",
    "\n",
    "        X = df.iloc[:, 0].fillna(' ')\n",
    "\n",
    "        tweets = X\n",
    "\n",
    "        num_of_tweets_analyzed = len(tweets)\n",
    "\n",
    "        sequences = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "        # Max number of words in a sequence\n",
    "        max_length = 37\n",
    "\n",
    "        padded = pad_sequences(\n",
    "            sequences, maxlen=max_length, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "        # Check reversing the indices\n",
    "\n",
    "        # flip (key, value)\n",
    "        reverse_word_index = dict([(idx, word)\n",
    "                                    for (word, idx) in word_index.items()])\n",
    "\n",
    "        def decode(sequence):\n",
    "            return \" \".join([reverse_word_index.get(idx, \"?\") for idx in sequence])\n",
    "\n",
    "        predictions = model.predict(padded)\n",
    "        \n",
    "        # Only for BinaryCrossentropy\n",
    "        predictions = [1 if p > 0.5 else 0 for p in predictions]\n",
    "        \n",
    "        # saving tweets to csv\n",
    "        tweets.to_csv(f'../analysis/tweets-{lang}.csv')\n",
    "        # saving sentiment predictions to csv\n",
    "        np.savetxt(f'../analysis/predictions-{lang}.csv',\n",
    "                predictions, delimiter=',', fmt=('%s'))\n",
    "        # adding sentiment column to the beginning\n",
    "        df = pd.read_csv(\n",
    "            f'../analysis/predictions-{lang}.csv', header=None)\n",
    "        df.rename(columns={0: 'sentiment'}, inplace=True)\n",
    "        # save to new csv file\n",
    "        df.to_csv(\n",
    "            f'../analysis/predictions-{lang}.csv', index=False)\n",
    "        # merging tweets and predictions\n",
    "        filenames = [f'../analysis/tweets-{lang}.csv',\n",
    "                    f'../analysis/predictions-{lang}.csv']\n",
    "        dfs = []\n",
    "        for filename in filenames:\n",
    "            # read the csv, making sure the first two columns are str\n",
    "            df = pd.read_csv(filename, header=None,\n",
    "                            converters={0: str, 1: str})\n",
    "            # change the column names so they won't collide during concatenation\n",
    "            df.columns = [filename + str(cname) for cname in df.columns]\n",
    "            dfs.append(df)\n",
    "        # concatenate them horizontally\n",
    "        merged = pd.concat(dfs, axis=1)\n",
    "        # write it out\n",
    "        merged.to_csv(\n",
    "            f\"../analysis/merged-{lang}.csv\", header=None, index=None)\n",
    "        df = pd.read_csv(f'../analysis/merged-{lang}.csv')\n",
    "        title_type = df.groupby('sentiment').agg('count')\n",
    "        type_labels = ['positive', 'negative']\n",
    "        type_counts = title_type.tweet.sort_values()\n",
    "        colors = ['g', 'r']\n",
    "        plt.subplot(\n",
    "            aspect=1, title=f'Classified {num_of_tweets_analyzed} tweets.')\n",
    "        type_show_ids = plt.pie(type_counts, labels=type_labels,\n",
    "                                autopct='%1.1f%%', shadow=True, colors=colors)\n",
    "        plt.savefig(f\"../visuals/{lang}.png\")\n",
    "    \n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# models_dir = '../models/NN_model_seven_12008898266757515530_0.7899888157844543'\n",
    "# tokenizers_dir = '../tokenizers/12008898266757515530.pkl'\n",
    "# model = load_model(models_dir)\n",
    "# model.summary()\n",
    "# tokenizer = joblib.load(tokenizers_dir)\n",
    "# word_index = tokenizer.word_index\n",
    "# for vaccine in vaccines:\n",
    "#     \n",
    "#     \n",
    "#     # already processed\n",
    "#     df = pd.read_csv(f'../vaccines/{vaccine}.csv', delimiter=',')\n",
    "#     df = df.drop_duplicates()\n",
    "#     df = df[['tweet', 'sentiment']]\n",
    "#     \n",
    "#     \n",
    "#     \n",
    "#     \n",
    "\n",
    "#     X = df.iloc[:, 0].fillna(' ')\n",
    "\n",
    "#     tweets = X\n",
    "\n",
    "#     num_of_tweets_analyzed = len(tweets)\n",
    "\n",
    "#     sequences = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "#     # Max number of words in a sequence\n",
    "#     max_length = 37\n",
    "\n",
    "#     padded = pad_sequences(\n",
    "#           sequences, maxlen=max_length, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "#     # Check reversing the indices\n",
    "\n",
    "#     # flip (key, value)\n",
    "#     reverse_word_index = dict([(idx, word)\n",
    "#                                   for (word, idx) in word_index.items()])\n",
    "\n",
    "#     def decode(sequence):\n",
    "#         return \" \".join([reverse_word_index.get(idx, \"?\") for idx in sequence])\n",
    "\n",
    "#     predictions = model.predict(padded)\n",
    "\n",
    "#     # Only for BinaryCrossentropy\n",
    "#     predictions = [1 if p > 0.5 else 0 for p in predictions]\n",
    "#     # saving tweets to csv\n",
    "#     tweets.to_csv(f'../analysis/tweets-{vaccine}.csv')\n",
    "#     # saving sentiment predictions to csv\n",
    "#     np.savetxt(f'../analysis/predictions-{vaccine}.csv',\n",
    "#                predictions, delimiter=',', fmt=('%s'))\n",
    "#     # adding sentiment column to the beginning\n",
    "#     df = pd.read_csv(\n",
    "#         f'../analysis/predictions-{vaccine}.csv', header=None)\n",
    "#     df.rename(columns={0: 'sentiment'}, inplace=True)\n",
    "#     # save to new csv file\n",
    "#     df.to_csv(\n",
    "#          f'../analysis/predictions-{vaccine}.csv', index=False)\n",
    "#     # merging tweets and predictions\n",
    "#     filenames = [f'../analysis/tweets-{vaccine}.csv',\n",
    "#                    f'../analysis/predictions-{vaccine}.csv']\n",
    "#     dfs = []\n",
    "#     for filename in filenames:\n",
    "#         # read the csv, making sure the first two columns are str\n",
    "#         df = pd.read_csv(filename, header=None,\n",
    "#                          converters={0: str, 1: str})\n",
    "#         # change the column names so they won't collide during concatenation\n",
    "#         df.columns = [filename + str(cname) for cname in df.columns]\n",
    "#         dfs.append(df)\n",
    "#     # concatenate them horizontally\n",
    "#     merged = pd.concat(dfs, axis=1)\n",
    "#     # write it out\n",
    "#     merged.to_csv(\n",
    "#         f\"../analysis/merged-{vaccine}.csv\", header=None, index=None)\n",
    "#     df = pd.read_csv(f'../analysis/merged-{vaccine}.csv')\n",
    "#     labels = ['negative', 'positive']\n",
    "#     title_type = df.groupby('sentiment').agg('count')\n",
    "#     type_labels = ['positive', 'negative']\n",
    "#     type_counts = title_type.tweet.sort_values()\n",
    "#     colors = ['g', 'r']\n",
    "#     plt.subplot(\n",
    "#         aspect=1, title=f'Percentage of tweets pro or against vaccination in {month.capitalize()} {year}\\nClassified {num_of_tweets_analyzed} tweets.')\n",
    "#     type_show_ids = plt.pie(type_counts, labels=type_labels,\n",
    "#                             autopct='%1.1f%%', shadow=True, colors=colors)\n",
    "#     plt.savefig(f\"../visuals/{vaccine}.png\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f595b24bd0005ade19c9cc9195ebfd43399e9f8b470abdede700a27b5c9ee90b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
