{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>awww bummer shoulda got david carr third day</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>upset cant updat facebook text might cri resul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dive mani time ball manag save 50 rest go bound</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>whole bodi feel itchi like fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>behav im mad whi becaus cant see</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  sentiment\n",
       "0       awww bummer shoulda got david carr third day          0\n",
       "1  upset cant updat facebook text might cri resul...          0\n",
       "2    dive mani time ball manag save 50 rest go bound          0\n",
       "3                    whole bodi feel itchi like fire          0\n",
       "4                   behav im mad whi becaus cant see          0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dir = 'sentiment140'\n",
    "# dataset_dir = 'imdb'\n",
    "# dataset_dir = 'coronaNLP'\n",
    "\n",
    "n_gram = (1, 2)\n",
    "\n",
    "# importing the processed dataframe\n",
    "df = joblib.load(f'../dataframes/df_{dataset_dir}.pkl')\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0               awww bummer shoulda got david carr third day\n",
       " 1          upset cant updat facebook text might cri resul...\n",
       " 2            dive mani time ball manag save 50 rest go bound\n",
       " 3                            whole bodi feel itchi like fire\n",
       " 4                           behav im mad whi becaus cant see\n",
       "                                  ...                        \n",
       " 1599995                           woke school best feel ever\n",
       " 1599996      thewdbcom veri cool hear old walt interview â«\n",
       " 1599997                         readi mojo makeov ask detail\n",
       " 1599998    happi 38th birthday boo alll time tupac amaru ...\n",
       " 1599999                                 happi charitytuesday\n",
       " Name: tweet, Length: 1583691, dtype: object,\n",
       " 0          0\n",
       " 1          0\n",
       " 2          0\n",
       " 3          0\n",
       " 4          0\n",
       "           ..\n",
       " 1599995    1\n",
       " 1599996    1\n",
       " 1599997    1\n",
       " 1599998    1\n",
       " 1599999    1\n",
       " Name: sentiment, Length: 1583691, dtype: int32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X = df.iloc[:, 0]\n",
    "\n",
    "\n",
    "y = df.iloc[:, 1]\n",
    "\n",
    "X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_features=402749, ngram_range=(1, 2), stop_words='english',\n",
       "                tokenizer=<bound method RegexpTokenizer.tokenize of RegexpTokenizer(pattern='[a-zA-Z0-9]+', gaps=False, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>)>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tfidf = joblib.load(\n",
    "    f\"../vectors/vectorizer_{dataset_dir}_{n_gram}.pkl\")\n",
    "tfidf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1108583, 402749), (1108583,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X = tfidf.transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "X_train.shape, y_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = []\n",
    "estimators.append(('MNB', MultinomialNB()))\n",
    "estimators.append(('CNB', ComplementNB()))\n",
    "# estimators.append(('XGB',\n",
    "#                   xgb.XGBClassifier(max_depth=50, use_label_encoder=False)))\n",
    "estimators.append(('LSVC', LinearSVC()))\n",
    "estimators.append(('LRG', LogisticRegression()))\n",
    "\n",
    "models = [\n",
    "    MultinomialNB(),\n",
    "    ComplementNB(),\n",
    "    # xgb.XGBClassifier(max_depth=50, use_label_encoder=False),\n",
    "    LinearSVC(),\n",
    "    LogisticRegression(),\n",
    "    VotingClassifier(estimators=estimators, voting='hard'),\n",
    "]\n",
    "\n",
    "model_to_use = 0\n",
    "\n",
    "model_idx = model_to_use\n",
    "\n",
    "# model_name = str(models[model_idx]).split('(')[0]\n",
    "# model_name += 'S'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, model in enumerate(models):\n",
    "#     model_name = str(models[i])[:-2]\n",
    "#     print(f\"-----Training {model_name}-----\")\n",
    "#     clf = model\n",
    "#     clf.fit(X_train, y_train)\n",
    "#     cross_clf = cross_val_score(clf, X, y)\n",
    "#     print(\"Cross Validation score = \", cross_clf)\n",
    "#     train_acc_clf = clf.score(X_train, y_train)\n",
    "#     test_acc_clf = clf.score(X_test, y_test)\n",
    "#     print(\"Train accuracy ={:.2f}%\".format(train_acc_clf*100))\n",
    "#     print(\"Test accuracy ={:.2f}%\".format(test_acc_clf*100))\n",
    "#     y_pred = clf.predict(X_test)\n",
    "#     print(classification_report(y_test, y_pred))\n",
    "#     acc = int(accuracy_score(y_test, y_pred)*100)\n",
    "#     print(\"ACC: \", acc)\n",
    "#     joblib.dump(clf,\n",
    "#                 f'../models/{model_name}_{dataset_dir}_{acc}.pkl')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8216615264711798\n",
      "0.8208027725483793\n",
      "0.8801731579863664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Enes\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8260779752170113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Enes\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8331139842483603\n"
     ]
    }
   ],
   "source": [
    "# for i, model in enumerate(models):\n",
    "#     model_name = str(model).split('(')[0]\n",
    "#     clf = model\n",
    "#     clf = clf.fit(X_train, y_train)\n",
    "#     # y_pred = clf.predict(X_test)\n",
    "#     train_acc_clf = clf.score(X_train, y_train)\n",
    "#     print(train_acc_clf)\n",
    "#     # print(classification_report(y_test, y_pred))\n",
    "#     # acc = int(accuracy_score(y_test, y_pred)*100)\n",
    "#     # joblib.dump(clf,\n",
    "#     #             f'../models/{model_name}_{dataset_dir}_{acc}_{n_gram}.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\n",
    "    {\n",
    "        'fit_prior': (False, True),\n",
    "        'alpha': (1, 0.1, 0.01, 0.001)\n",
    "    }, \n",
    "    {\n",
    "        'fit_prior': (False, True),\n",
    "        'norm': (False, True),\n",
    "        'alpha': (1, 0.1, 0.01, 0.001)\n",
    "    },\n",
    "    {\n",
    "        'booster': ('gbtree', 'gblinear', 'dart'),\n",
    "        'eta': (0.1, 0, 25, 0.4, 0.5), \n",
    "    },\n",
    "    {\n",
    "        'C': ('1', '0.5', '0.25'),\n",
    "        'kernel': ('rfb', 'linear', 'poly', 'sigmoid'),\n",
    "    },\n",
    "    {\n",
    "        'penalty': ('l2', 'none'),\n",
    "        'C': np.logspace(-4, 4, 10),\n",
    "        'solver': ('sag', 'saga', 'newton-cg'),\n",
    "        'max_iter': (100, 1000, 2500, 5000)\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = models[model_idx]\n",
    "\n",
    "# parameters = params[model_idx]\n",
    "\n",
    "# clf = GridSearchCV(clf, param_grid=parameters, scoring='accuracy', cv=5, verbose=True) if model_idx != -1 else clf\n",
    "# clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf = clf.fit(X_train, y_train)\n",
    "# clf.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fig, ax = plt.subplots(figsize=(30, 30))\n",
    "# xgb.plot_tree(clf, num_trees=4, ax=ax)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.77    237056\n",
      "           1       0.77      0.78      0.77    238052\n",
      "\n",
      "    accuracy                           0.77    475108\n",
      "   macro avg       0.77      0.77      0.77    475108\n",
      "weighted avg       0.77      0.77      0.77    475108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_probs = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12190435, 0.87809565],\n",
       "       [0.18118281, 0.81881719],\n",
       "       [0.28937892, 0.71062108],\n",
       "       ...,\n",
       "       [0.57378174, 0.42621826],\n",
       "       [0.45363124, 0.54636876],\n",
       "       [0.11549447, 0.88450553]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(\"Best: %f using %s\" % (clf.best_score_,\n",
    "#                              clf.best_params_))\n",
    "# means = clf.cv_results_['mean_test_score']\n",
    "# stds = clf.cv_results_['std_test_score']\n",
    "# params = clf.cv_results_['params']\n",
    "# for mean, stdev, param in zip(means, stds, params):\n",
    "#     print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "acc = int(accuracy_score(y_test, y_pred)*100)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_tweet = \"groceri store\"\n",
    "# vector = tfidf.transform([test_tweet])\n",
    "\n",
    "# print(clf.predict(vector))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# exporting the pipeline\n",
    "joblib.dump(clf,\n",
    "            f'../models/mnb_{dataset_dir}_{acc}_{n_gram}.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "599e51aa143538ccec1c7ab4b528efe64565e20e387dbc49eb00bf436cfb223b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
