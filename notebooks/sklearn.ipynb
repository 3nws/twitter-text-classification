{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "dataset_dir = 'sentiment140'\n",
    "# dataset_dir = 'imdb'\n",
    "# dataset_dir = 'coronaNLP'\n",
    "\n",
    "n_gram = (1, 2)\n",
    "\n",
    "# importing the processed dataframe\n",
    "df = joblib.load(f'../dataframes/df_{dataset_dir}.pkl')\n",
    "\n",
    "df.head()\n",
    "\n",
    "\n",
    "X = df.iloc[:, 0]\n",
    "\n",
    "\n",
    "y = df.iloc[:, 1]\n",
    "\n",
    "X, y\n",
    "\n",
    "\n",
    "tfidf = joblib.load(\n",
    "    f\"../vectors/vectorizer_{dataset_dir}_{n_gram}.pkl\")\n",
    "tfidf\n",
    "\n",
    "\n",
    "X = tfidf.transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "X_train.shape, y_train.shape\n",
    "\n",
    "estimators = []\n",
    "estimators.append(('MNB', MultinomialNB()))\n",
    "estimators.append(('CNB', ComplementNB()))\n",
    "# estimators.append(('XGB',\n",
    "#                   xgb.XGBClassifier(max_depth=50, use_label_encoder=False)))\n",
    "estimators.append(('LSVC', LinearSVC()))\n",
    "estimators.append(('LRG', LogisticRegression()))\n",
    "\n",
    "models = [\n",
    "    MultinomialNB(),\n",
    "    ComplementNB(),\n",
    "    # xgb.XGBClassifier(max_depth=50, use_label_encoder=False),\n",
    "    LinearSVC(),\n",
    "    LogisticRegression(),\n",
    "    VotingClassifier(estimators=estimators, voting='hard'),\n",
    "]\n",
    "\n",
    "model_to_use = 0\n",
    "\n",
    "model_idx = model_to_use\n",
    "\n",
    "# model_name = str(models[model_idx]).split('(')[0]\n",
    "# model_name += 'S'\n",
    "# for i, model in enumerate(models):\n",
    "#     model_name = str(models[i])[:-2]\n",
    "#     print(f\"-----Training {model_name}-----\")\n",
    "#     clf = model\n",
    "#     clf.fit(X_train, y_train)\n",
    "#     cross_clf = cross_val_score(clf, X, y)\n",
    "#     print(\"Cross Validation score = \", cross_clf)\n",
    "#     train_acc_clf = clf.score(X_train, y_train)\n",
    "#     test_acc_clf = clf.score(X_test, y_test)\n",
    "#     print(\"Train accuracy ={:.2f}%\".format(train_acc_clf*100))\n",
    "#     print(\"Test accuracy ={:.2f}%\".format(test_acc_clf*100))\n",
    "#     y_pred = clf.predict(X_test)\n",
    "#     print(classification_report(y_test, y_pred))\n",
    "#     acc = int(accuracy_score(y_test, y_pred)*100)\n",
    "#     print(\"ACC: \", acc)\n",
    "#     joblib.dump(clf,\n",
    "#                 f'../models/{model_name}_{dataset_dir}_{acc}.pkl')\n",
    "    \n",
    "# for i, model in enumerate(models):\n",
    "#     model_name = str(model).split('(')[0]\n",
    "#     clf = model\n",
    "#     clf = clf.fit(X_train, y_train)\n",
    "#     # y_pred = clf.predict(X_test)\n",
    "#     train_acc_clf = clf.score(X_train, y_train)\n",
    "#     print(train_acc_clf)\n",
    "#     # print(classification_report(y_test, y_pred))\n",
    "#     # acc = int(accuracy_score(y_test, y_pred)*100)\n",
    "#     # joblib.dump(clf,\n",
    "#     #             f'../models/{model_name}_{dataset_dir}_{acc}_{n_gram}.pkl')\n",
    "\n",
    "# params = [\n",
    "#     {\n",
    "#         'fit_prior': (False, True),\n",
    "#         'alpha': (1, 0.1, 0.01, 0.001)\n",
    "#     }, \n",
    "#     {\n",
    "#         'fit_prior': (False, True),\n",
    "#         'norm': (False, True),\n",
    "#         'alpha': (1, 0.1, 0.01, 0.001)\n",
    "#     },\n",
    "#     {\n",
    "#         'booster': ('gbtree', 'gblinear', 'dart'),\n",
    "#         'eta': (0.1, 0, 25, 0.4, 0.5), \n",
    "#     },\n",
    "#     {\n",
    "#         'C': ('1', '0.5', '0.25'),\n",
    "#         'kernel': ('rfb', 'linear', 'poly', 'sigmoid'),\n",
    "#     },\n",
    "#     {\n",
    "#         'penalty': ('l2', 'none'),\n",
    "#         'C': np.logspace(-4, 4, 10),\n",
    "#         'solver': ('sag', 'saga', 'newton-cg'),\n",
    "#         'max_iter': (100, 1000, 2500, 5000)\n",
    "#     }\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    clf = models[i]\n",
    "    print(\"==============================\")\n",
    "    model_name = str(models[i]).split('(')[0]\n",
    "    print(f\"==============={model_name}===============\")\n",
    "    # parameters = params[model_idx]\n",
    "\n",
    "    # clf = GridSearchCV(clf, param_grid=parameters, scoring='accuracy', cv=5, verbose=True) if model_idx != -1 else clf\n",
    "    # clf\n",
    "\n",
    "\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    # clf.best_estimator_\n",
    "\n",
    "\n",
    "    # fig, ax = plt.subplots(figsize=(30, 30))\n",
    "    # xgb.plot_tree(clf, num_trees=4, ax=ax)\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    # if i==2:\n",
    "    #     print(\"ROC AUC: \", roc_auc_score(y_test, y_pred, multi_class='ovr'))\n",
    "    # else:\n",
    "    #     print(\"ROC AUC: \", roc_auc_score(y_test, y_pred))\n",
    "        \n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # prediction_probs = clf.predict_proba(X_test)\n",
    "    # prediction_probs\n",
    "\n",
    "    # print(\"Best: %f using %s\" % (clf.best_score_,\n",
    "    #                              clf.best_params_))\n",
    "    # means = clf.cv_results_['mean_test_score']\n",
    "    # stds = clf.cv_results_['std_test_score']\n",
    "    # params = clf.cv_results_['params']\n",
    "    # for mean, stdev, param in zip(means, stds, params):\n",
    "    #     print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "\n",
    "    # test_acc = accuracy_score(y_test, y_pred)\n",
    "    # y_pred = clf.predict(X_train)\n",
    "    # train_acc = accuracy_score(y_train, y_pred)\n",
    "    # print(\"TEST: \", test_acc, \"TRAIN: \", train_acc)\n",
    "    print(\"==============================\")\n",
    "    # test_tweet = \"groceri store\"\n",
    "    # vector = tfidf.transform([test_tweet])\n",
    "\n",
    "    # print(clf.predict(vector))\n",
    "\n",
    "\n",
    "    # exporting the pipeline\n",
    "    # joblib.dump(clf,\n",
    "    #             f'../models/mnb_{dataset_dir}_{acc}_{n_gram}.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f595b24bd0005ade19c9cc9195ebfd43399e9f8b470abdede700a27b5c9ee90b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
